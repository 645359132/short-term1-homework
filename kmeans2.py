import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
from data import CHINA_DATA

warnings.filterwarnings("ignore")

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡
plt.rcParams["font.sans-serif"] = ["SimHei", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False


def simple_kmeans(X, k=3, max_iters=100):
    """ç®€å•çš„K-meanså®ç°"""
    np.random.seed(42)

    # éšæœºåˆå§‹åŒ–èšç±»ä¸­å¿ƒ
    centroids = X[np.random.choice(X.shape[0], k, replace=False)]

    for _ in range(max_iters):
        # è®¡ç®—æ¯ä¸ªç‚¹åˆ°èšç±»ä¸­å¿ƒçš„è·ç¦»
        distances = np.sqrt(((X - centroids[:, np.newaxis]) ** 2).sum(axis=2))
        # åˆ†é…åˆ°æœ€è¿‘çš„èšç±»ä¸­å¿ƒ
        labels = np.argmin(distances, axis=0)

        # æ›´æ–°èšç±»ä¸­å¿ƒ
        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])

        # æ£€æŸ¥æ”¶æ•›
        if np.allclose(centroids, new_centroids):
            break

        centroids = new_centroids

    return labels, centroids


def prepare_city_features(data):
    """å‡†å¤‡åŸå¸‚ç‰¹å¾"""
    print("å‡†å¤‡åŸå¸‚ç‰¹å¾...")

    city_features = []

    for city in data["city_name"].unique():
        city_data = data[data["city_name"] == city]

        # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
        total_emission = city_data["value"].sum()
        mean_emission = city_data["value"].mean()
        std_emission = city_data["value"].std() if len(city_data) > 1 else 0

        # åœ°ç†ç‰¹å¾
        lat = city_data["lat"].iloc[0] if "lat" in city_data.columns else 0
        lon = city_data["lon"].iloc[0] if "lon" in city_data.columns else 0

        # æ—¶é—´ç‰¹å¾
        years_count = city_data["year"].nunique()

        # è¶‹åŠ¿è®¡ç®—
        yearly_sum = city_data.groupby("year")["value"].sum()
        if len(yearly_sum) > 1:
            years = yearly_sum.index.values
            values = yearly_sum.values
            # ç®€å•çº¿æ€§å›å½’è®¡ç®—è¶‹åŠ¿
            x_mean = np.mean(years)
            y_mean = np.mean(values)
            slope = np.sum((years - x_mean) * (values - y_mean)) / np.sum(
                (years - x_mean) ** 2
            )
        else:
            slope = 0

        city_features.append(
            [total_emission, mean_emission, std_emission, lat, lon, years_count, slope]
        )

    feature_names = [
        "total_emission",
        "mean_emission",
        "std_emission",
        "lat",
        "lon",
        "years_count",
        "trend_slope",
    ]

    cities = data["city_name"].unique()

    return np.array(city_features), cities, feature_names


def normalize_features(X):
    """æ ‡å‡†åŒ–ç‰¹å¾"""
    mean = np.mean(X, axis=0)
    std = np.std(X, axis=0)
    return (X - mean) / (std + 1e-8)


def analyze_and_visualize(data):
    """åˆ†æå¹¶å¯è§†åŒ–ï¼ˆç‰¹å¾è¯´æ˜å¢å¼ºç‰ˆï¼‰"""
    print("å¼€å§‹åˆ†æ...")

    # å‡†å¤‡ç‰¹å¾
    X, cities, feature_names = prepare_city_features(data)
    print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
    print(f"èšç±»ä½¿ç”¨çš„7ä¸ªç‰¹å¾: {feature_names}")

    # ç‰¹å¾è¯¦ç»†è¯´æ˜
    feature_descriptions = {
        "total_emission": "æ€»æ’æ”¾é‡ (ä¸‡å¨COâ‚‚)",
        "mean_emission": "å¹³å‡å¹´æ’æ”¾é‡ (ä¸‡å¨COâ‚‚/å¹´)",
        "std_emission": "æ’æ”¾é‡æ ‡å‡†å·® (æ³¢åŠ¨æ€§)",
        "lat": "çº¬åº¦ (åœ°ç†ä½ç½®-å—åŒ—)",
        "lon": "ç»åº¦ (åœ°ç†ä½ç½®-ä¸œè¥¿)",
        "years_count": "æ•°æ®å¹´ä»½æ•°é‡ (æ•°æ®å®Œæ•´æ€§)",
        "trend_slope": "æ’æ”¾è¶‹åŠ¿æ–œç‡ (æ—¶é—´å˜åŒ–ç‡)",
    }

    print("\nğŸ¯ èšç±»ç‰¹å¾è¯¦ç»†è¯´æ˜:")
    print("=" * 50)
    for i, (name, desc) in enumerate(feature_descriptions.items()):
        print(f"ç‰¹å¾{i+1}: {desc}")
    print("=" * 50)
    print("ğŸ“Œ æ³¨æ„: K-meansèšç±»æ˜¯åŸºäºä»¥ä¸Š7ä¸ªç‰¹å¾çš„ç»¼åˆç›¸ä¼¼æ€§è¿›è¡Œçš„")
    print("ğŸ“Œ æ¯å¼ å›¾è¡¨ä»ä¸åŒç‰¹å¾ç»´åº¦å±•ç¤ºèšç±»ç»“æœ\n")

    # æ ‡å‡†åŒ–ç‰¹å¾
    X_normalized = normalize_features(X)

    # å¯»æ‰¾æœ€ä¼˜Kå€¼
    print("å¯»æ‰¾æœ€ä¼˜Kå€¼...")
    k_range = range(2, min(8, len(cities) // 2))
    inertias = []

    for k in k_range:
        labels, centroids = simple_kmeans(X_normalized, k=k)
        inertia = sum(
            [
                np.sum((X_normalized[labels == i] - centroids[i]) ** 2)
                for i in range(k)
                if np.sum(labels == i) > 0
            ]
        )
        inertias.append(inertia)
        print(f"K={k}: æƒ¯æ€§={inertia:.2f}")

    # å¯è§†åŒ–è‚˜éƒ¨æ³•åˆ™
    plt.figure(figsize=(12, 6))
    plt.plot(k_range, inertias, "bo-", linewidth=2, markersize=8)
    plt.xlabel("èšç±»æ•°é‡ (K)", fontsize=12)
    plt.ylabel("èšç±»æƒ¯æ€§å€¼ (Within-cluster Sum of Squares)", fontsize=12)
    plt.title(
        "è‚˜éƒ¨æ³•åˆ™ - åŸºäº7ç»´ç‰¹å¾çš„æœ€ä¼˜Kå€¼é€‰æ‹©\n"
        + "ç‰¹å¾: æ’æ”¾é‡ç»Ÿè®¡(3) + åœ°ç†ä½ç½®(2) + æ—¶é—´ç‰¹å¾(1) + è¶‹åŠ¿ç‰¹å¾(1)",
        fontsize=14,
        fontweight="bold",
    )
    plt.grid(True, alpha=0.3)

    # æ·»åŠ ç‰¹å¾è¯´æ˜æ–‡æœ¬æ¡†
    textstr = "èšç±»ç‰¹å¾:\nâ€¢ æ€»æ’æ”¾é‡ & å¹³å‡æ’æ”¾é‡ & æ’æ”¾æ³¢åŠ¨æ€§\nâ€¢ çº¬åº¦ & ç»åº¦\nâ€¢ æ•°æ®å¹´ä»½æ•°\nâ€¢ æ’æ”¾è¶‹åŠ¿æ–œç‡"
    props = dict(boxstyle="round", facecolor="lightblue", alpha=0.8)
    plt.text(
        0.02,
        0.98,
        textstr,
        transform=plt.gca().transAxes,
        fontsize=10,
        verticalalignment="top",
        bbox=props,
    )

    for i, (k, inertia) in enumerate(zip(k_range, inertias)):
        plt.annotate(
            f"{inertia:.1f}",
            (k, inertia),
            textcoords="offset points",
            xytext=(0, 10),
            ha="center",
        )

    plt.tight_layout()
    plt.show()

    # ä½¿ç”¨æœ€ä¼˜Kå€¼è¿›è¡Œèšç±»
    optimal_k = 4
    print(f"ä½¿ç”¨K={optimal_k}è¿›è¡Œèšç±»...")

    labels, centroids = simple_kmeans(X_normalized, k=optimal_k)

    # åˆ›å»ºç»“æœDataFrame
    results_df = pd.DataFrame(X, columns=feature_names)
    results_df["city_name"] = cities
    results_df["cluster"] = labels

    # è®¡ç®—èšç±»ç»Ÿè®¡
    cluster_stats = {}
    for i in range(optimal_k):
        mask = labels == i
        cluster_data = X[mask]
        cluster_cities = cities[mask]

        cluster_stats[i] = {
            "count": len(cluster_cities),
            "cities": cluster_cities[:3].tolist(),
            "total_emission_mean": cluster_data[:, 0].mean(),
            "mean_emission_mean": cluster_data[:, 1].mean(),
            "std_emission_mean": cluster_data[:, 2].mean(),
            "lat_mean": cluster_data[:, 3].mean(),
            "lon_mean": cluster_data[:, 4].mean(),
            "years_count_mean": cluster_data[:, 5].mean(),
            "trend_mean": cluster_data[:, 6].mean(),
            "trend_desc": (
                "ä¸Šå‡è¶‹åŠ¿"
                if cluster_data[:, 6].mean() > 0.1
                else "ä¸‹é™è¶‹åŠ¿" if cluster_data[:, 6].mean() < -0.1 else "ç›¸å¯¹ç¨³å®š"
            ),
        }

    # åˆ›å»ºå¢å¼ºç‰ˆå¯è§†åŒ–
    fig = plt.figure(figsize=(20, 16))
    fig.suptitle(
        f"åŸºäº7ç»´ç‰¹å¾çš„åŸå¸‚ç¢³æ’æ”¾K-meansèšç±»åˆ†æ (K={optimal_k})\n"
        + "èšç±»ç‰¹å¾: æ’æ”¾ç»Ÿè®¡ç‰¹å¾ + åœ°ç†ä½ç½®ç‰¹å¾ + æ—¶é—´ç‰¹å¾ + è¶‹åŠ¿ç‰¹å¾",
        fontsize=18,
        fontweight="bold",
        y=0.95,
    )

    # å®šä¹‰é¢œè‰²å’Œæ ‡è®°
    colors = plt.cm.Set1(np.linspace(0, 1, optimal_k))
    markers = ["o", "s", "^", "D", "v", "<", ">", "p"]

    # 1. åœ°ç†ä½ç½®ç‰¹å¾å±•ç¤º (ç‰¹å¾4,5: çº¬åº¦ã€ç»åº¦)
    ax1 = plt.subplot(2, 3, 1)
    for i in range(optimal_k):
        mask = labels == i
        scatter = ax1.scatter(
            X[mask, 4],
            X[mask, 3],
            c=[colors[i]],
            label=f'èšç±»{i} ({cluster_stats[i]["count"]}åŸå¸‚)',
            s=80,
            alpha=0.7,
            marker=markers[i],
            edgecolors="black",
            linewidth=0.5,
        )

    centroids_original = np.array(
        [X[labels == i].mean(axis=0) for i in range(optimal_k)]
    )
    ax1.scatter(
        centroids_original[:, 4],
        centroids_original[:, 3],
        c="red",
        marker="X",
        s=300,
        linewidths=2,
        label="èšç±»ä¸­å¿ƒ",
        edgecolors="black",
    )

    ax1.set_xlabel("ğŸŒ ç‰¹å¾5: ç»åº¦ (Longitude)", fontsize=12, fontweight="bold")
    ax1.set_ylabel("ğŸŒ ç‰¹å¾4: çº¬åº¦ (Latitude)", fontsize=12, fontweight="bold")
    ax1.set_title(
        "åœ°ç†ä½ç½®ç‰¹å¾èšç±»å±•ç¤º\nåŸºäº7ç»´ç‰¹å¾èšç±»ï¼Œå±•ç¤ºåœ°ç†ä½ç½®ç»´åº¦",
        fontsize=12,
        fontweight="bold",
        color="darkblue",
    )
    ax1.legend(bbox_to_anchor=(1.05, 1), loc="upper left", fontsize=9)
    ax1.grid(True, alpha=0.3)

    # æ·»åŠ ç‰¹å¾è¯´æ˜
    textstr = (
        "å±•ç¤ºç‰¹å¾:\nâ€¢ çº¬åº¦ (å—åŒ—ä½ç½®)\nâ€¢ ç»åº¦ (ä¸œè¥¿ä½ç½®)\n\nèšç±»ä¾æ®:\nåŸºäºå…¨éƒ¨7ä¸ªç‰¹å¾"
    )
    props = dict(boxstyle="round", facecolor="lightgreen", alpha=0.7)
    ax1.text(
        0.02,
        0.02,
        textstr,
        transform=ax1.transAxes,
        fontsize=8,
        verticalalignment="bottom",
        bbox=props,
    )

    # 2. æ’æ”¾é‡ç»Ÿè®¡ç‰¹å¾å±•ç¤º (ç‰¹å¾1,2: æ€»æ’æ”¾é‡ã€å¹³å‡æ’æ”¾é‡)
    ax2 = plt.subplot(2, 3, 2)
    for i in range(optimal_k):
        mask = labels == i
        scatter = ax2.scatter(
            X[mask, 0],
            X[mask, 1],
            c=[colors[i]],
            label=f'èšç±»{i}: {cluster_stats[i]["trend_desc"]}',
            s=80,
            alpha=0.7,
            marker=markers[i],
            edgecolors="black",
            linewidth=0.5,
        )

    ax2.scatter(
        centroids_original[:, 0],
        centroids_original[:, 1],
        c="red",
        marker="X",
        s=300,
        linewidths=2,
        label="èšç±»ä¸­å¿ƒ",
        edgecolors="black",
    )

    ax2.set_xlabel("ğŸ“Š ç‰¹å¾1: æ€»æ’æ”¾é‡ (ä¸‡å¨COâ‚‚)", fontsize=12, fontweight="bold")
    ax2.set_ylabel("ğŸ“Š ç‰¹å¾2: å¹³å‡æ’æ”¾é‡ (ä¸‡å¨COâ‚‚/å¹´)", fontsize=12, fontweight="bold")
    ax2.set_title(
        "æ’æ”¾é‡ç»Ÿè®¡ç‰¹å¾èšç±»å±•ç¤º\nåŸºäº7ç»´ç‰¹å¾èšç±»ï¼Œå±•ç¤ºæ’æ”¾é‡ç»Ÿè®¡ç»´åº¦",
        fontsize=12,
        fontweight="bold",
        color="darkgreen",
    )
    ax2.legend(bbox_to_anchor=(1.05, 1), loc="upper left", fontsize=9)
    ax2.grid(True, alpha=0.3)

    textstr = "å±•ç¤ºç‰¹å¾:\nâ€¢ æ€»æ’æ”¾é‡ (ç´¯è®¡)\nâ€¢ å¹³å‡æ’æ”¾é‡ (å¼ºåº¦)\n\nèšç±»ä¾æ®:\nåŸºäºå…¨éƒ¨7ä¸ªç‰¹å¾"
    props = dict(boxstyle="round", facecolor="lightcoral", alpha=0.7)
    ax2.text(
        0.02,
        0.98,
        textstr,
        transform=ax2.transAxes,
        fontsize=8,
        verticalalignment="top",
        bbox=props,
    )

    # 3. èšç±»æ•°é‡ç»Ÿè®¡
    ax3 = plt.subplot(2, 3, 3)
    unique, counts = np.unique(labels, return_counts=True)
    bars = ax3.bar(
        unique,
        counts,
        color=colors[: len(unique)],
        alpha=0.7,
        edgecolor="black",
        linewidth=2,
    )

    for i, (bar, count) in enumerate(zip(bars, counts)):
        height = bar.get_height()
        ax3.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 0.3,
            f"{count}åŸå¸‚\n({count/len(cities)*100:.1f}%)",
            ha="center",
            va="bottom",
            fontsize=11,
            fontweight="bold",
        )

    ax3.set_xlabel("èšç±»ç¼–å·", fontsize=12, fontweight="bold")
    ax3.set_ylabel("åŸå¸‚æ•°é‡", fontsize=12, fontweight="bold")
    ax3.set_title(
        "èšç±»è§„æ¨¡åˆ†å¸ƒ\nåŸºäº7ç»´ç‰¹å¾èšç±»çš„åŸå¸‚åˆ†é…æƒ…å†µ",
        fontsize=12,
        fontweight="bold",
        color="darkorange",
    )
    ax3.set_xticks(unique)
    ax3.grid(True, alpha=0.3, axis="y")

    # 4. è¶‹åŠ¿ç‰¹å¾å±•ç¤º (ç‰¹å¾7: è¶‹åŠ¿æ–œç‡)
    ax4 = plt.subplot(2, 3, 4)
    trend_means = [cluster_stats[i]["trend_mean"] for i in range(optimal_k)]
    bars = ax4.bar(
        range(optimal_k),
        trend_means,
        color=colors,
        alpha=0.7,
        edgecolor="black",
        linewidth=2,
    )

    for i, (bar, trend) in enumerate(zip(bars, trend_means)):
        height = bar.get_height()
        y_pos = height + 0.002 if height >= 0 else height - 0.004
        ax4.text(
            bar.get_x() + bar.get_width() / 2.0,
            y_pos,
            f'{trend:.3f}\n{cluster_stats[i]["trend_desc"]}',
            ha="center",
            va="bottom" if height >= 0 else "top",
            fontsize=9,
            fontweight="bold",
        )

    ax4.axhline(y=0, color="red", linestyle="--", alpha=0.8, linewidth=2)
    ax4.set_xlabel("èšç±»ç¼–å·", fontsize=12, fontweight="bold")
    ax4.set_ylabel("ğŸ“ˆ ç‰¹å¾7: è¶‹åŠ¿æ–œç‡ (ä¸‡å¨COâ‚‚/å¹´Â²)", fontsize=12, fontweight="bold")
    ax4.set_title(
        "æ’æ”¾è¶‹åŠ¿ç‰¹å¾èšç±»å±•ç¤º\nåŸºäº7ç»´ç‰¹å¾èšç±»ï¼Œå±•ç¤ºæ—¶é—´è¶‹åŠ¿ç»´åº¦",
        fontsize=12,
        fontweight="bold",
        color="darkred",
    )
    ax4.grid(True, alpha=0.3)

    textstr = "å±•ç¤ºç‰¹å¾:\nâ€¢ æ’æ”¾è¶‹åŠ¿æ–œç‡\n  (æ­£å€¼=ä¸Šå‡è¶‹åŠ¿)\n  (è´Ÿå€¼=ä¸‹é™è¶‹åŠ¿)\n\nèšç±»ä¾æ®:\nåŸºäºå…¨éƒ¨7ä¸ªç‰¹å¾"
    props = dict(boxstyle="round", facecolor="lightpink", alpha=0.7)
    ax4.text(
        0.02,
        0.02,
        textstr,
        transform=ax4.transAxes,
        fontsize=8,
        verticalalignment="bottom",
        bbox=props,
    )

    # 5. æ’æ”¾æ³¢åŠ¨æ€§ç‰¹å¾å±•ç¤º (ç‰¹å¾3: æ ‡å‡†å·®)
    ax5 = plt.subplot(2, 3, 5)
    std_means = [cluster_stats[i]["std_emission_mean"] for i in range(optimal_k)]
    bars = ax5.bar(
        range(optimal_k),
        std_means,
        color=colors,
        alpha=0.7,
        edgecolor="black",
        linewidth=2,
    )

    for i, (bar, std_val) in enumerate(zip(bars, std_means)):
        height = bar.get_height()
        ax5.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + height * 0.02,
            f"{std_val:.2f}",
            ha="center",
            va="bottom",
            fontsize=10,
            fontweight="bold",
        )

    ax5.set_xlabel("èšç±»ç¼–å·", fontsize=12, fontweight="bold")
    ax5.set_ylabel("ğŸ“Š ç‰¹å¾3: æ’æ”¾æ ‡å‡†å·® (æ³¢åŠ¨æ€§)", fontsize=12, fontweight="bold")
    ax5.set_title(
        "æ’æ”¾æ³¢åŠ¨æ€§ç‰¹å¾èšç±»å±•ç¤º\nåŸºäº7ç»´ç‰¹å¾èšç±»ï¼Œå±•ç¤ºæ’æ”¾ç¨³å®šæ€§ç»´åº¦",
        fontsize=12,
        fontweight="bold",
        color="darkviolet",
    )
    ax5.grid(True, alpha=0.3)

    textstr = "å±•ç¤ºç‰¹å¾:\nâ€¢ æ’æ”¾é‡æ ‡å‡†å·®\n  (æ•°å€¼è¶Šå¤§=æ³¢åŠ¨è¶Šå¤§)\n  (æ•°å€¼è¶Šå°=æ’æ”¾è¶Šç¨³å®š)\n\nèšç±»ä¾æ®:\nåŸºäºå…¨éƒ¨7ä¸ªç‰¹å¾"
    props = dict(boxstyle="round", facecolor="plum", alpha=0.7)
    ax5.text(
        0.02,
        0.98,
        textstr,
        transform=ax5.transAxes,
        fontsize=8,
        verticalalignment="top",
        bbox=props,
    )

    # 6. æ•°æ®å®Œæ•´æ€§ç‰¹å¾å±•ç¤º (ç‰¹å¾6: å¹´ä»½æ•°é‡)
    ax6 = plt.subplot(2, 3, 6)
    years_means = [cluster_stats[i]["years_count_mean"] for i in range(optimal_k)]
    bars = ax6.bar(
        range(optimal_k),
        years_means,
        color=colors,
        alpha=0.7,
        edgecolor="black",
        linewidth=2,
    )

    for i, (bar, years_val) in enumerate(zip(bars, years_means)):
        height = bar.get_height()
        ax6.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + height * 0.02,
            f"{years_val:.1f}å¹´",
            ha="center",
            va="bottom",
            fontsize=10,
            fontweight="bold",
        )

    ax6.set_xlabel("èšç±»ç¼–å·", fontsize=12, fontweight="bold")
    ax6.set_ylabel("ğŸ“… ç‰¹å¾6: æ•°æ®å¹´ä»½æ•°é‡", fontsize=12, fontweight="bold")
    ax6.set_title(
        "æ•°æ®å®Œæ•´æ€§ç‰¹å¾èšç±»å±•ç¤º\nåŸºäº7ç»´ç‰¹å¾èšç±»ï¼Œå±•ç¤ºæ•°æ®è´¨é‡ç»´åº¦",
        fontsize=12,
        fontweight="bold",
        color="darkcyan",
    )
    ax6.grid(True, alpha=0.3)

    textstr = "å±•ç¤ºç‰¹å¾:\nâ€¢ æ•°æ®å¹´ä»½æ•°é‡\n  (æ•°å€¼è¶Šå¤§=æ•°æ®è¶Šå®Œæ•´)\n  (å½±å“èšç±»å¯é æ€§)\n\nèšç±»ä¾æ®:\nåŸºäºå…¨éƒ¨7ä¸ªç‰¹å¾"
    props = dict(boxstyle="round", facecolor="lightcyan", alpha=0.7)
    ax6.text(
        0.02,
        0.02,
        textstr,
        transform=ax6.transAxes,
        fontsize=8,
        verticalalignment="bottom",
        bbox=props,
    )

    plt.tight_layout()
    plt.show()

    # åˆ›å»º7ç»´ç‰¹å¾ç»¼åˆå±•ç¤ºå›¾
    fig, ax = plt.subplots(figsize=(14, 10))

    # é›·è¾¾å›¾æ˜¾ç¤ºå„èšç±»åœ¨7ä¸ªç‰¹å¾ä¸Šçš„è¡¨ç°
    feature_labels_chinese = [
        "æ€»æ’æ”¾é‡",
        "å¹³å‡æ’æ”¾é‡",
        "æ’æ”¾æ³¢åŠ¨æ€§",
        "çº¬åº¦",
        "ç»åº¦",
        "æ•°æ®å¹´ä»½",
        "æ’æ”¾è¶‹åŠ¿",
    ]
    angles = np.linspace(0, 2 * np.pi, 7, endpoint=False).tolist()
    angles += angles[:1]  # é—­åˆ

    for i in range(optimal_k):
        cluster_data = X_normalized[labels == i]
        if len(cluster_data) > 0:
            radar_values = [cluster_data[:, j].mean() for j in range(7)]
            radar_values += radar_values[:1]  # é—­åˆ

            ax.plot(
                angles,
                radar_values,
                "o-",
                linewidth=3,
                label=f'èšç±»{i} ({cluster_stats[i]["count"]}åŸå¸‚)',
                color=colors[i],
                alpha=0.8,
                markersize=8,
            )
            ax.fill(angles, radar_values, alpha=0.15, color=colors[i])

    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(feature_labels_chinese, fontsize=12, fontweight="bold")
    ax.set_title(
        "7ç»´ç‰¹å¾ç»¼åˆé›·è¾¾å›¾\nå±•ç¤ºå„èšç±»åœ¨æ‰€æœ‰èšç±»ç‰¹å¾ä¸Šçš„è¡¨ç°æ¨¡å¼\n(æ•°å€¼å·²æ ‡å‡†åŒ–: 0ä¸ºå¹³å‡æ°´å¹³)",
        fontsize=16,
        fontweight="bold",
        pad=30,
    )
    ax.legend(bbox_to_anchor=(1.2, 1), loc="upper left", fontsize=11)
    ax.grid(True, alpha=0.3)

    # æ·»åŠ ç‰¹å¾è¯´æ˜
    feature_explanation = """
    7ä¸ªèšç±»ç‰¹å¾è¯´æ˜:
    â€¢ æ€»æ’æ”¾é‡: åŸå¸‚ç´¯è®¡ç¢³æ’æ”¾æ€»é‡
    â€¢ å¹³å‡æ’æ”¾é‡: åŸå¸‚å¹´å‡ç¢³æ’æ”¾å¼ºåº¦  
    â€¢ æ’æ”¾æ³¢åŠ¨æ€§: æ’æ”¾é‡å¹´é™…å˜åŒ–ç¨‹åº¦
    â€¢ çº¬åº¦&ç»åº¦: åŸå¸‚åœ°ç†ä½ç½®åæ ‡
    â€¢ æ•°æ®å¹´ä»½: æ•°æ®æ—¶é—´è·¨åº¦é•¿åº¦
    â€¢ æ’æ”¾è¶‹åŠ¿: æ’æ”¾é‡éšæ—¶é—´å˜åŒ–æ–œç‡
    
    é›·è¾¾å›¾è§£è¯»:
    â€¢ å„è½´æ•°å€¼ä¸ºæ ‡å‡†åŒ–åç»“æœ
    â€¢ æ•°å€¼ä¸ºæ­£: é«˜äºå¹³å‡æ°´å¹³
    â€¢ æ•°å€¼ä¸ºè´Ÿ: ä½äºå¹³å‡æ°´å¹³
    â€¢ å›¾å½¢é¢ç§¯: åæ˜ èšç±»ç‰¹å¾å¼ºåº¦
    """

    ax.text(
        1.3,
        0.5,
        feature_explanation,
        transform=ax.transAxes,
        fontsize=10,
        verticalalignment="center",
        bbox=dict(boxstyle="round,pad=1", facecolor="lightyellow", alpha=0.9),
    )

    plt.tight_layout()
    plt.show()

    # è¾“å‡ºè¯¦ç»†çš„ç‰¹å¾èšç±»è¯´æ˜
    print("\n" + "ğŸ¯" * 30)
    print("ç‰¹å¾èšç±»è¯¦ç»†åˆ†ææŠ¥å‘Š")
    print("ğŸ¯" * 30)
    print(f"\nğŸ“‹ èšç±»æ–¹æ³•: K-meansç®—æ³• (K={optimal_k})")
    print("ğŸ“‹ èšç±»ä¾æ®: åŒæ—¶è€ƒè™‘ä»¥ä¸‹7ä¸ªç‰¹å¾çš„ç»¼åˆç›¸ä¼¼æ€§")
    print("-" * 60)

    for i, (name, desc) in enumerate(feature_descriptions.items()):
        print(f"  ç‰¹å¾{i+1}: {desc}")

    print("\nğŸ“Š èšç±»ç»“æœè§£è¯»:")
    print("-" * 60)
    print("â€¢ ç›¸åŒèšç±»çš„åŸå¸‚åœ¨7ä¸ªç‰¹å¾ä¸Šå…·æœ‰ç›¸ä¼¼æ¨¡å¼")
    print("â€¢ ä¸åŒèšç±»ä»£è¡¨ä¸åŒçš„åŸå¸‚æ’æ”¾ç‰¹å¾ç»„åˆ")
    print("â€¢ æ¯å¼ å›¾è¡¨ä»ä¸åŒè§’åº¦å±•ç¤ºåŒä¸€èšç±»ç»“æœ")

    for i in range(optimal_k):
        cluster_cities = cities[labels == i]
        cluster_data = X[labels == i]

        print(f"\nğŸ™ï¸  èšç±» {i} ç‰¹å¾ç”»åƒ")
        print("-" * 50)
        print(f"ğŸ“ åŸå¸‚æ•°é‡: {len(cluster_cities)} ä¸ª")
        print(f"ğŸ“ ä»£è¡¨åŸå¸‚: {', '.join(cluster_stats[i]['cities'])}")

        print(f"\nğŸ“ˆ 7ç»´ç‰¹å¾è¡¨ç°:")
        for j, (name, desc) in enumerate(feature_descriptions.items()):
            value = cluster_data[:, j].mean()
            normalized_value = X_normalized[labels == i, j].mean()
            level = (
                "é«˜äºå¹³å‡"
                if normalized_value > 0.5
                else "ä½äºå¹³å‡" if normalized_value < -0.5 else "æ¥è¿‘å¹³å‡"
            )
            print(f"  â€¢ {desc}: {value:.2f} ({level})")

        # èšç±»ç‰¹å¾æ€»ç»“
        print(f"\nğŸ¯ èšç±»ç‰¹å¾æ€»ç»“:")
        emission_level = (
            "é«˜æ’æ”¾"
            if cluster_stats[i]["mean_emission_mean"] > 30
            else "ä¸­æ’æ”¾" if cluster_stats[i]["mean_emission_mean"] > 10 else "ä½æ’æ”¾"
        )
        stability = (
            "æ³¢åŠ¨å¤§" if cluster_stats[i]["std_emission_mean"] > 20 else "ç›¸å¯¹ç¨³å®š"
        )
        print(f"  â€¢ æ’æ”¾æ°´å¹³: {emission_level}")
        print(f"  â€¢ æ’æ”¾ç¨³å®šæ€§: {stability}")
        print(f"  â€¢ å‘å±•è¶‹åŠ¿: {cluster_stats[i]['trend_desc']}")
        print(
            f"  â€¢ åœ°ç†åˆ†å¸ƒ: çº¬åº¦{cluster_stats[i]['lat_mean']:.1f}Â°, ç»åº¦{cluster_stats[i]['lon_mean']:.1f}Â°"
        )

    return results_df


def linear_trend_with_confidence(time_series, future_years, confidence=0.95):
    """çº¿æ€§è¶‹åŠ¿é¢„æµ‹ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰"""
    x = np.arange(len(time_series))
    y = time_series["value"].values

    # çº¿æ€§å›å½’
    x_mean = np.mean(x)
    y_mean = np.mean(y)
    slope = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean) ** 2)
    intercept = y_mean - slope * x_mean

    # é¢„æµ‹æœªæ¥
    future_x = np.arange(len(time_series), len(time_series) + future_years)
    future_pred = slope * future_x + intercept

    # è®¡ç®—RÂ²
    y_pred = slope * x + intercept
    ss_res = np.sum((y - y_pred) ** 2)
    ss_tot = np.sum((y - y_mean) ** 2)
    r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

    # è®¡ç®—ç½®ä¿¡åŒºé—´
    residuals = y - y_pred
    mse = np.mean(residuals**2)

    # æ ‡å‡†è¯¯å·®
    se = np.sqrt(
        mse * (1 + 1 / len(x) + (future_x - x_mean) ** 2 / np.sum((x - x_mean) ** 2))
    )

    # ç®€åŒ–çš„ç½®ä¿¡åŒºé—´ï¼ˆä½¿ç”¨1.96ä½œä¸ºè¿‘ä¼¼tå€¼ï¼‰
    margin_error = 1.96 * se

    return {
        "predictions": future_pred,
        "upper_bound": future_pred + margin_error,
        "lower_bound": future_pred - margin_error,
        "r_squared": r_squared,
        "slope": slope,
        "method": "Linear Trend",
    }


def polynomial_trend_prediction(time_series, future_years, degree=2):
    """å¤šé¡¹å¼è¶‹åŠ¿é¢„æµ‹"""
    x = np.arange(len(time_series))
    y = time_series["value"].values

    # é€‰æ‹©æœ€ä½³å¤šé¡¹å¼åº¦æ•°
    best_degree = 1
    best_score = -np.inf

    for d in range(1, min(4, len(time_series) // 3)):  # é¿å…è¿‡æ‹Ÿåˆ
        coeffs = np.polyfit(x, y, d)
        poly_pred = np.polyval(coeffs, x)

        # è®¡ç®—è°ƒæ•´åçš„RÂ²
        ss_res = np.sum((y - poly_pred) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
        adj_r_squared = 1 - (1 - r_squared) * (len(y) - 1) / (len(y) - d - 1)

        if adj_r_squared > best_score:
            best_score = adj_r_squared
            best_degree = d

    # ä½¿ç”¨æœ€ä½³åº¦æ•°è¿›è¡Œé¢„æµ‹
    coeffs = np.polyfit(x, y, best_degree)
    future_x = np.arange(len(time_series), len(time_series) + future_years)
    future_pred = np.polyval(coeffs, future_x)

    return {
        "predictions": future_pred,
        "degree": best_degree,
        "r_squared": best_score,
        "method": f"Polynomial (degree {best_degree})",
    }


def moving_average_prediction(time_series, future_years, window=None):
    """ç§»åŠ¨å¹³å‡é¢„æµ‹"""
    values = time_series["value"].values

    if window is None:
        window = min(max(3, len(values) // 4), 12)  # è‡ªé€‚åº”çª—å£å¤§å°

    # è®¡ç®—ç§»åŠ¨å¹³å‡
    if len(values) < window:
        window = len(values)

    moving_avg = np.convolve(values, np.ones(window) / window, mode="valid")

    # è®¡ç®—è¶‹åŠ¿
    if len(moving_avg) > 1:
        x = np.arange(len(moving_avg))
        x_mean = np.mean(x)
        y_mean = np.mean(moving_avg)
        slope = np.sum((x - x_mean) * (moving_avg - y_mean)) / np.sum((x - x_mean) ** 2)

        # é¢„æµ‹æœªæ¥
        last_avg = moving_avg[-1]
        future_pred = []
        for i in range(future_years):
            next_pred = last_avg + slope * (i + 1)
            future_pred.append(next_pred)

        return {
            "predictions": np.array(future_pred),
            "window_size": window,
            "trend_slope": slope,
            "method": f"Moving Average (window={window})",
        }
    else:
        return {
            "predictions": np.full(future_years, values[-1]),
            "method": "Simple Average",
        }


def exponential_smoothing_prediction(time_series, future_years, alpha=0.3):
    """æŒ‡æ•°å¹³æ»‘é¢„æµ‹"""
    values = time_series["value"].values

    # åº”ç”¨æŒ‡æ•°å¹³æ»‘
    smoothed = [values[0]]
    for i in range(1, len(values)):
        smoothed.append(alpha * values[i] + (1 - alpha) * smoothed[i - 1])

    smoothed = np.array(smoothed)

    # è®¡ç®—è¶‹åŠ¿
    trend = smoothed[-1] - smoothed[-2] if len(smoothed) > 1 else 0

    # é¢„æµ‹æœªæ¥
    future_pred = []
    last_value = smoothed[-1]

    for i in range(future_years):
        next_pred = last_value + trend * (i + 1)
        future_pred.append(next_pred)

    return {
        "predictions": np.array(future_pred),
        "alpha": alpha,
        "trend": trend,
        "method": f"Exponential Smoothing (Î±={alpha:.2f})",
    }


def ensemble_prediction(predictions, future_years):
    """é›†æˆé¢„æµ‹ï¼ˆå¤šæ¨¡å‹å¹³å‡ï¼‰"""
    # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„é¢„æµ‹
    valid_predictions = []
    weights = []
    methods = []

    for method, pred_data in predictions.items():
        if method != "ensemble" and "predictions" in pred_data:
            valid_predictions.append(pred_data["predictions"])
            methods.append(pred_data["method"])

            # æ ¹æ®æ–¹æ³•çš„å¯é æ€§è®¾ç½®æƒé‡
            if "r_squared" in pred_data:
                weight = max(pred_data["r_squared"], 0.1)  # æœ€å°æƒé‡0.1
            else:
                weight = 1.0
            weights.append(weight)

    if not valid_predictions:
        return {
            "predictions": np.zeros(future_years),
            "method": "Ensemble (no valid predictions)",
        }

    # å½’ä¸€åŒ–æƒé‡
    weights = np.array(weights)
    weights = weights / np.sum(weights)

    # åŠ æƒå¹³å‡
    ensemble_pred = np.zeros(future_years)
    for pred, weight in zip(valid_predictions, weights):
        if len(pred) == future_years:
            ensemble_pred += weight * pred

    return {
        "predictions": ensemble_pred,
        "weights": dict(zip(methods, weights)),
        "method": "Ensemble Average",
    }


def perform_multiple_predictions(time_series, future_years):
    """æ‰§è¡Œå¤šç§é¢„æµ‹æ–¹æ³•"""
    predictions = {}

    # 1. çº¿æ€§è¶‹åŠ¿é¢„æµ‹ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰
    predictions["linear"] = linear_trend_with_confidence(time_series, future_years)

    # 2. å¤šé¡¹å¼è¶‹åŠ¿é¢„æµ‹
    predictions["polynomial"] = polynomial_trend_prediction(time_series, future_years)

    # 3. ç§»åŠ¨å¹³å‡é¢„æµ‹
    predictions["moving_average"] = moving_average_prediction(time_series, future_years)

    # 4. æŒ‡æ•°å¹³æ»‘é¢„æµ‹
    predictions["exponential"] = exponential_smoothing_prediction(
        time_series, future_years
    )

    # 5. é›†æˆé¢„æµ‹ï¼ˆå¤šæ¨¡å‹å¹³å‡ï¼‰
    predictions["ensemble"] = ensemble_prediction(predictions, future_years)

    return predictions


def enhanced_prediction(data, results_df, future_years=5):
    """å¢å¼ºç‰ˆè¶‹åŠ¿é¢„æµ‹"""
    print(f"\næœªæ¥{future_years}å¹´å¢å¼ºè¶‹åŠ¿é¢„æµ‹:")
    print("=" * 80)

    for cluster_id in sorted(results_df["cluster"].unique()):
        cluster_cities = results_df[results_df["cluster"] == cluster_id][
            "city_name"
        ].tolist()
        cluster_data = data[data["city_name"].isin(cluster_cities)]

        print(f"\nèšç±» {cluster_id} - åŒ…å« {len(cluster_cities)} ä¸ªåŸå¸‚")
        print("-" * 60)

        # æŒ‰å¹´èšåˆ
        time_series = cluster_data.groupby("year").agg({"value": "sum"}).reset_index()
        time_series["date"] = pd.to_datetime(time_series["year"], format="%Y")
        time_series = time_series.sort_values("date").reset_index(drop=True)

        if len(time_series) < 3:
            print(f"æ•°æ®ç‚¹å¤ªå°‘ ({len(time_series)} ä¸ª)ï¼Œè·³è¿‡é¢„æµ‹")
            continue

        # æ‰§è¡Œå¤šç§é¢„æµ‹æ–¹æ³•
        predictions = perform_multiple_predictions(time_series, future_years)

        # å¯è§†åŒ–ç»“æœ
        visualize_enhanced_predictions(
            time_series, predictions, cluster_id, future_years
        )

        # æ‰“å°é¢„æµ‹æ‘˜è¦
        print_prediction_summary(predictions, time_series)


def visualize_enhanced_predictions(time_series, predictions, cluster_id, future_years):
    """å¯è§†åŒ–å¢å¼ºé¢„æµ‹ç»“æœ"""
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f"èšç±» {cluster_id} - å¤šæ¨¡å‹ç¢³æ’æ”¾é¢„æµ‹åˆ†æ", fontsize=16)

    historical_dates = time_series["date"]
    historical_values = time_series["value"]

    # åˆ›å»ºæœªæ¥æ—¥æœŸ
    last_date = historical_dates.iloc[-1]
    future_dates = pd.date_range(
        start=last_date + pd.DateOffset(years=1), periods=future_years, freq="YS"
    )

    # 1. çº¿æ€§è¶‹åŠ¿ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰
    ax1 = axes[0, 0]
    ax1.plot(historical_dates, historical_values, "b-", label="å†å²æ•°æ®", linewidth=2)

    if "linear" in predictions:
        linear_pred = predictions["linear"]
        ax1.plot(
            future_dates,
            linear_pred["predictions"],
            "r--",
            label=f"çº¿æ€§é¢„æµ‹ (RÂ²={linear_pred['r_squared']:.3f})",
            linewidth=2,
        )
        ax1.fill_between(
            future_dates,
            linear_pred["lower_bound"],
            linear_pred["upper_bound"],
            alpha=0.3,
            color="red",
            label="95%ç½®ä¿¡åŒºé—´",
        )

    ax1.set_title("çº¿æ€§è¶‹åŠ¿é¢„æµ‹ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰")
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.tick_params(axis="x", rotation=45)

    # 2. å¤šé¡¹å¼é¢„æµ‹
    ax2 = axes[0, 1]
    ax2.plot(historical_dates, historical_values, "b-", label="å†å²æ•°æ®", linewidth=2)

    if "polynomial" in predictions:
        poly_pred = predictions["polynomial"]
        ax2.plot(
            future_dates,
            poly_pred["predictions"],
            "g--",
            label=f"{poly_pred['method']}",
            linewidth=2,
        )

    if "moving_average" in predictions:
        ma_pred = predictions["moving_average"]
        ax2.plot(
            future_dates,
            ma_pred["predictions"],
            "m--",
            label=f"{ma_pred['method']}",
            linewidth=2,
        )

    ax2.set_title("å¤šé¡¹å¼ä¸ç§»åŠ¨å¹³å‡é¢„æµ‹")
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.tick_params(axis="x", rotation=45)

    # 3. æŒ‡æ•°å¹³æ»‘é¢„æµ‹
    ax3 = axes[1, 0]
    ax3.plot(historical_dates, historical_values, "b-", label="å†å²æ•°æ®", linewidth=2)

    if "exponential" in predictions:
        exp_pred = predictions["exponential"]
        ax3.plot(
            future_dates,
            exp_pred["predictions"],
            "orange",
            linestyle="--",
            label=f"{exp_pred['method']}",
            linewidth=2,
        )

    ax3.set_title("æŒ‡æ•°å¹³æ»‘é¢„æµ‹")
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.tick_params(axis="x", rotation=45)

    # 4. é›†æˆé¢„æµ‹å¯¹æ¯”
    ax4 = axes[1, 1]
    ax4.plot(historical_dates, historical_values, "b-", label="å†å²æ•°æ®", linewidth=3)

    # æ˜¾ç¤ºå¤šç§é¢„æµ‹æ–¹æ³•
    colors = ["red", "green", "orange", "purple", "brown"]
    i = 0
    for method, pred_data in predictions.items():
        if "predictions" in pred_data and i < len(colors):
            ax4.plot(
                future_dates,
                pred_data["predictions"],
                color=colors[i],
                linestyle="--",
                alpha=0.7,
                label=pred_data["method"],
                linewidth=1.5,
            )
            i += 1

    # çªå‡ºæ˜¾ç¤ºé›†æˆé¢„æµ‹
    if "ensemble" in predictions:
        ensemble_pred = predictions["ensemble"]
        ax4.plot(
            future_dates,
            ensemble_pred["predictions"],
            "black",
            linestyle="-",
            label="é›†æˆé¢„æµ‹",
            linewidth=3,
        )

    ax4.set_title("æ‰€æœ‰é¢„æµ‹æ–¹æ³•å¯¹æ¯”")
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.tick_params(axis="x", rotation=45)

    plt.tight_layout()
    plt.show()


def print_prediction_summary(predictions, time_series):
    """æ‰“å°é¢„æµ‹æ‘˜è¦"""
    historical_mean = time_series["value"].mean()

    print("é¢„æµ‹æ–¹æ³•å¯¹æ¯”:")
    print("-" * 50)

    for method, pred_data in predictions.items():
        if "predictions" in pred_data:
            future_mean = np.mean(pred_data["predictions"])
            change_percent = ((future_mean - historical_mean) / historical_mean) * 100

            print(f"{pred_data['method']}:")
            print(f"  æœªæ¥å¹³å‡é¢„æµ‹å€¼: {future_mean:.2f}")
            print(f"  ç›¸æ¯”å†å²å¹³å‡å˜åŒ–: {change_percent:+.1f}%")

            if "r_squared" in pred_data:
                print(f"  æ¨¡å‹æ‹Ÿåˆåº¦ (RÂ²): {pred_data['r_squared']:.3f}")

            if method == "linear" and "slope" in pred_data:
                trend = (
                    "ä¸Šå‡"
                    if pred_data["slope"] > 0
                    else "ä¸‹é™" if pred_data["slope"] < 0 else "ç¨³å®š"
                )
                print(f"  è¶‹åŠ¿æ–¹å‘: {trend}")

            print()


# ==================== ä¸»æ‰§è¡Œå‡½æ•° ====================


def create_plots():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ç¢³æ’æ”¾K-meansèšç±»åˆ†æ...")

    # æ£€æŸ¥æ•°æ®
    print(f"æ•°æ®å½¢çŠ¶: {CHINA_DATA.shape}")
    print(f"æ•°æ®åˆ—: {CHINA_DATA.columns.tolist()}")
    print(f"åŸå¸‚æ•°é‡: {CHINA_DATA['city_name'].nunique()}")

    # æ‰§è¡Œèšç±»åˆ†æ
    results = analyze_and_visualize(CHINA_DATA)

    # æ‰§è¡Œå¢å¼ºç‰ˆè¶‹åŠ¿é¢„æµ‹
    enhanced_prediction(CHINA_DATA, results, future_years=5)

    print("\nåˆ†æå®Œæˆï¼")
