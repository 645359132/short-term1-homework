import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
from data import CHINA_DATA

warnings.filterwarnings("ignore")

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡
plt.rcParams["font.sans-serif"] = ["SimHei", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False


def simple_kmeans(X, k=3, max_iters=100):
    """ç®€å•çš„K-meanså®ç°"""
    np.random.seed(42)

    # éšæœºåˆå§‹åŒ–èšç±»ä¸­å¿ƒ
    centroids = X[np.random.choice(X.shape[0], k, replace=False)]

    for _ in range(max_iters):
        # è®¡ç®—æ¯ä¸ªç‚¹åˆ°èšç±»ä¸­å¿ƒçš„è·ç¦»
        distances = np.sqrt(((X - centroids[:, np.newaxis]) ** 2).sum(axis=2))
        # åˆ†é…åˆ°æœ€è¿‘çš„èšç±»ä¸­å¿ƒ
        labels = np.argmin(distances, axis=0)

        # æ›´æ–°èšç±»ä¸­å¿ƒ
        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])

        # æ£€æŸ¥æ”¶æ•›
        if np.allclose(centroids, new_centroids):
            break

        centroids = new_centroids

    return labels, centroids


def prepare_city_features(data):
    """å‡†å¤‡åŸå¸‚ç‰¹å¾"""
    print("å‡†å¤‡åŸå¸‚ç‰¹å¾...")

    city_features = []

    for city in data["city_name"].unique():
        city_data = data[data["city_name"] == city]

        # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
        total_emission = city_data["value"].sum()
        mean_emission = city_data["value"].mean()
        std_emission = city_data["value"].std() if len(city_data) > 1 else 0

        # åœ°ç†ç‰¹å¾
        lat = city_data["lat"].iloc[0] if "lat" in city_data.columns else 0
        lon = city_data["lon"].iloc[0] if "lon" in city_data.columns else 0

        # æ—¶é—´ç‰¹å¾
        years_count = city_data["year"].nunique()

        # è¶‹åŠ¿è®¡ç®—
        yearly_sum = city_data.groupby("year")["value"].sum()
        if len(yearly_sum) > 1:
            years = yearly_sum.index.values
            values = yearly_sum.values
            # ç®€å•çº¿æ€§å›å½’è®¡ç®—è¶‹åŠ¿
            x_mean = np.mean(years)
            y_mean = np.mean(values)
            slope = np.sum((years - x_mean) * (values - y_mean)) / np.sum(
                (years - x_mean) ** 2
            )
        else:
            slope = 0

        city_features.append(
            [total_emission, mean_emission, std_emission, lat, lon, years_count, slope]
        )

    feature_names = [
        "total_emission",
        "mean_emission",
        "std_emission",
        "lat",
        "lon",
        "years_count",
        "trend_slope",
    ]

    cities = data["city_name"].unique()

    return np.array(city_features), cities, feature_names


def normalize_features(X):
    """æ ‡å‡†åŒ–ç‰¹å¾"""
    mean = np.mean(X, axis=0)
    std = np.std(X, axis=0)
    return (X - mean) / (std + 1e-8)


def analyze_and_visualize(data):
    """åˆ†æå¹¶å¯è§†åŒ–ï¼ˆç‰¹å¾è¯´æ˜å¢å¼ºç‰ˆï¼‰"""
    print("å¼€å§‹åˆ†æ...")

    # å‡†å¤‡ç‰¹å¾
    X, cities, feature_names = prepare_city_features(data)
    print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")

    # ç‰¹å¾è¯¦ç»†è¯´æ˜ (åªåœ¨æ­¤å¤„è¯¦ç»†æ‰“å°ä¸€æ¬¡)
    feature_descriptions = {
        "total_emission": "æ€»æ’æ”¾é‡ (ä¸‡å¨COâ‚‚)",
        "mean_emission": "å¹³å‡å¹´æ’æ”¾é‡ (ä¸‡å¨COâ‚‚/å¹´)",
        "std_emission": "æ’æ”¾é‡æ ‡å‡†å·® (æ³¢åŠ¨æ€§)",
        "lat": "çº¬åº¦ (åœ°ç†ä½ç½®-å—åŒ—)",
        "lon": "ç»åº¦ (åœ°ç†ä½ç½®-ä¸œè¥¿)",
        "years_count": "æ•°æ®å¹´ä»½æ•°é‡ (æ•°æ®å®Œæ•´æ€§)",
        "trend_slope": "æ’æ”¾è¶‹åŠ¿æ–œç‡ (æ—¶é—´å˜åŒ–ç‡)",
    }

    print("\nğŸ¯ èšç±»ä½¿ç”¨çš„7ä¸ªç‰¹å¾è¯¦ç»†è¯´æ˜:")
    print("=" * 50)
    for i, (name, desc) in enumerate(feature_descriptions.items()):
        print(f"ç‰¹å¾{i + 1}: {name:<15} - {desc}")
    print("=" * 50)
    print("ğŸ“Œ K-meansèšç±»å°†åŸºäºä»¥ä¸Š7ä¸ªç‰¹å¾çš„ç»¼åˆç›¸ä¼¼æ€§è¿›è¡Œ")
    print("ğŸ“Œ ç¨åç”Ÿæˆçš„å›¾è¡¨å°†ä»ä¸åŒç»´åº¦å±•ç¤ºèšç±»ç»“æœ\n")

    # æ ‡å‡†åŒ–ç‰¹å¾
    X_normalized = normalize_features(X)

    # å¯»æ‰¾æœ€ä¼˜Kå€¼
    print("å¯»æ‰¾æœ€ä¼˜Kå€¼ (è‚˜éƒ¨æ³•åˆ™)...")
    k_range = range(2, min(8, len(cities) // 2))
    inertias = []

    for k in k_range:
        labels, centroids = simple_kmeans(X_normalized, k=k)
        inertia = sum(
            [
                np.sum((X_normalized[labels == i] - centroids[i]) ** 2)
                for i in range(k)
                if np.sum(labels == i) > 0
            ]
        )
        inertias.append(inertia)
        print(f"  K={k}: æƒ¯æ€§={inertia:.2f}")

    # å¯è§†åŒ–è‚˜éƒ¨æ³•åˆ™
    plt.figure(figsize=(12, 6))
    plt.plot(k_range, inertias, "bo-", linewidth=2, markersize=8)
    plt.xlabel("èšç±»æ•°é‡ (K)", fontsize=12)
    plt.ylabel("èšç±»æƒ¯æ€§å€¼ (Within-cluster Sum of Squares)", fontsize=12)
    plt.title(
        "è‚˜éƒ¨æ³•åˆ™ - åŸºäº7ç»´ç‰¹å¾çš„æœ€ä¼˜Kå€¼é€‰æ‹©\n"
        + "ç‰¹å¾: æ’æ”¾é‡ç»Ÿè®¡(3) + åœ°ç†ä½ç½®(2) + æ—¶é—´ç‰¹å¾(1) + è¶‹åŠ¿ç‰¹å¾(1)",
        fontsize=14,
        fontweight="bold",
    )
    plt.grid(True, alpha=0.3)

    textstr = "èšç±»ç‰¹å¾:\nâ€¢ æ€»æ’æ”¾é‡ & å¹³å‡æ’æ”¾é‡ & æ’æ”¾æ³¢åŠ¨æ€§\nâ€¢ çº¬åº¦ & ç»åº¦\nâ€¢ æ•°æ®å¹´ä»½æ•°\nâ€¢ æ’æ”¾è¶‹åŠ¿æ–œç‡"
    props = dict(boxstyle="round", facecolor="lightblue", alpha=0.8)
    plt.text(
        0.02,
        0.98,
        textstr,
        transform=plt.gca().transAxes,
        fontsize=10,
        verticalalignment="top",
        bbox=props,
    )

    for i, (k, inertia) in enumerate(zip(k_range, inertias)):
        plt.annotate(
            f"{inertia:.1f}",
            (k, inertia),
            textcoords="offset points",
            xytext=(0, 10),
            ha="center",
        )

    plt.tight_layout()
    plt.show()

    # ä½¿ç”¨æœ€ä¼˜Kå€¼è¿›è¡Œèšç±»
    optimal_k = 4
    print(f"\næ ¹æ®è‚˜éƒ¨æ³•åˆ™ï¼Œé€‰æ‹©K={optimal_k}è¿›è¡Œæœ€ç»ˆèšç±»...")

    labels, centroids = simple_kmeans(X_normalized, k=optimal_k)

    # åˆ›å»ºç»“æœDataFrame
    results_df = pd.DataFrame(X, columns=feature_names)
    results_df["city_name"] = cities
    results_df["cluster"] = labels

    # è®¡ç®—èšç±»ç»Ÿè®¡
    cluster_stats = {}
    for i in range(optimal_k):
        mask = labels == i
        cluster_data = X[mask]
        cluster_cities = cities[mask]

        cluster_stats[i] = {
            "count": len(cluster_cities),
            "cities": cluster_cities[:3].tolist(),
            "total_emission_mean": cluster_data[:, 0].mean(),
            "mean_emission_mean": cluster_data[:, 1].mean(),
            "std_emission_mean": cluster_data[:, 2].mean(),
            "lat_mean": cluster_data[:, 3].mean(),
            "lon_mean": cluster_data[:, 4].mean(),
            "years_count_mean": cluster_data[:, 5].mean(),
            "trend_mean": cluster_data[:, 6].mean(),
            "trend_desc": (
                "ä¸Šå‡è¶‹åŠ¿"
                if cluster_data[:, 6].mean() > 0.1
                else "ä¸‹é™è¶‹åŠ¿" if cluster_data[:, 6].mean() < -0.1 else "ç›¸å¯¹ç¨³å®š"
            ),
        }

    # åˆ›å»ºå¢å¼ºç‰ˆå¯è§†åŒ–
    fig = plt.figure(figsize=(20, 16))
    fig.suptitle(
        f"åŸºäº7ç»´ç‰¹å¾çš„åŸå¸‚ç¢³æ’æ”¾K-meansèšç±»åˆ†æ (K={optimal_k})\n"
        + "èšç±»ç‰¹å¾: æ’æ”¾ç»Ÿè®¡ç‰¹å¾ + åœ°ç†ä½ç½®ç‰¹å¾ + æ—¶é—´ç‰¹å¾ + è¶‹åŠ¿ç‰¹å¾",
        fontsize=18,
        fontweight="bold",
        y=0.95,
    )

    colors = plt.cm.Set1(np.linspace(0, 1, optimal_k))
    markers = ["o", "s", "^", "D", "v", "<", ">", "p"]

    # 1. åœ°ç†ä½ç½®ç‰¹å¾å±•ç¤º (ç‰¹å¾4,5: çº¬åº¦ã€ç»åº¦)
    ax1 = plt.subplot(2, 3, 1)
    for i in range(optimal_k):
        mask = labels == i
        ax1.scatter(
            X[mask, 4],
            X[mask, 3],
            c=[colors[i]],
            label=f'èšç±»{i} ({cluster_stats[i]["count"]}åŸå¸‚)',
            s=80,
            alpha=0.7,
            marker=markers[i],
            edgecolors="black",
            linewidth=0.5,
        )
    centroids_original = np.array(
        [X[labels == i].mean(axis=0) for i in range(optimal_k)]
    )
    ax1.scatter(
        centroids_original[:, 4],
        centroids_original[:, 3],
        c="red",
        marker="X",
        s=300,
        linewidths=2,
        label="èšç±»ä¸­å¿ƒ",
        edgecolors="black",
    )
    ax1.set_xlabel("ğŸŒ ç‰¹å¾5: ç»åº¦ (Longitude)", fontsize=12, fontweight="bold")
    ax1.set_ylabel("ğŸŒ ç‰¹å¾4: çº¬åº¦ (Latitude)", fontsize=12, fontweight="bold")
    ax1.set_title(
        "åœ°ç†ä½ç½®ç‰¹å¾èšç±»å±•ç¤º", fontsize=12, fontweight="bold", color="darkblue"
    )
    ax1.legend(bbox_to_anchor=(1.05, 1), loc="upper left", fontsize=9)
    ax1.grid(True, alpha=0.3)

    # 2. æ’æ”¾é‡ç»Ÿè®¡ç‰¹å¾å±•ç¤º (ç‰¹å¾1,2: æ€»æ’æ”¾é‡ã€å¹³å‡æ’æ”¾é‡)
    ax2 = plt.subplot(2, 3, 2)
    for i in range(optimal_k):
        mask = labels == i
        ax2.scatter(
            X[mask, 0],
            X[mask, 1],
            c=[colors[i]],
            label=f'èšç±»{i}: {cluster_stats[i]["trend_desc"]}',
            s=80,
            alpha=0.7,
            marker=markers[i],
            edgecolors="black",
            linewidth=0.5,
        )
    ax2.scatter(
        centroids_original[:, 0],
        centroids_original[:, 1],
        c="red",
        marker="X",
        s=300,
        linewidths=2,
        label="èšç±»ä¸­å¿ƒ",
        edgecolors="black",
    )
    ax2.set_xlabel("ğŸ“Š ç‰¹å¾1: æ€»æ’æ”¾é‡ (ä¸‡å¨COâ‚‚)", fontsize=12, fontweight="bold")
    ax2.set_ylabel("ğŸ“Š ç‰¹å¾2: å¹³å‡æ’æ”¾é‡ (ä¸‡å¨COâ‚‚/å¹´)", fontsize=12, fontweight="bold")
    ax2.set_title(
        "æ’æ”¾é‡ç»Ÿè®¡ç‰¹å¾èšç±»å±•ç¤º", fontsize=12, fontweight="bold", color="darkgreen"
    )
    ax2.legend(bbox_to_anchor=(1.05, 1), loc="upper left", fontsize=9)
    ax2.grid(True, alpha=0.3)

    # 3. èšç±»æ•°é‡ç»Ÿè®¡
    ax3 = plt.subplot(2, 3, 3)
    unique, counts = np.unique(labels, return_counts=True)
    bars = ax3.bar(
        unique,
        counts,
        color=colors[: len(unique)],
        alpha=0.7,
        edgecolor="black",
        linewidth=2,
    )
    for bar, count in zip(bars, counts):
        height = bar.get_height()
        ax3.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 0.3,
            f"{count}åŸå¸‚\n({count / len(cities) * 100:.1f}%)",
            ha="center",
            va="bottom",
            fontsize=11,
            fontweight="bold",
        )
    ax3.set_xlabel("èšç±»ç¼–å·", fontsize=12, fontweight="bold")
    ax3.set_ylabel("åŸå¸‚æ•°é‡", fontsize=12, fontweight="bold")
    ax3.set_title("èšç±»è§„æ¨¡åˆ†å¸ƒ", fontsize=12, fontweight="bold", color="darkorange")
    ax3.set_xticks(unique)
    ax3.grid(True, alpha=0.3, axis="y")

    # 4. è¶‹åŠ¿ç‰¹å¾å±•ç¤º (ç‰¹å¾7: è¶‹åŠ¿æ–œç‡)
    ax4 = plt.subplot(2, 3, 4)
    trend_means = [cluster_stats[i]["trend_mean"] for i in range(optimal_k)]
    bars = ax4.bar(
        range(optimal_k),
        trend_means,
        color=colors,
        alpha=0.7,
        edgecolor="black",
        linewidth=2,
    )
    for i, (bar, trend) in enumerate(zip(bars, trend_means)):
        height = bar.get_height()
        y_pos = height + 0.002 if height >= 0 else height - 0.004
        ax4.text(
            bar.get_x() + bar.get_width() / 2.0,
            y_pos,
            f'{trend:.3f}\n{cluster_stats[i]["trend_desc"]}',
            ha="center",
            va="bottom" if height >= 0 else "top",
            fontsize=9,
            fontweight="bold",
        )
    ax4.axhline(y=0, color="red", linestyle="--", alpha=0.8, linewidth=2)
    ax4.set_xlabel("èšç±»ç¼–å·", fontsize=12, fontweight="bold")
    ax4.set_ylabel("ğŸ“ˆ ç‰¹å¾7: è¶‹åŠ¿æ–œç‡ (ä¸‡å¨COâ‚‚/å¹´Â²)", fontsize=12, fontweight="bold")
    ax4.set_title(
        "æ’æ”¾è¶‹åŠ¿ç‰¹å¾èšç±»å±•ç¤º", fontsize=12, fontweight="bold", color="darkred"
    )
    ax4.grid(True, alpha=0.3)

    # 5. æ’æ”¾æ³¢åŠ¨æ€§ç‰¹å¾å±•ç¤º (ç‰¹å¾3: æ ‡å‡†å·®)
    ax5 = plt.subplot(2, 3, 5)
    std_means = [cluster_stats[i]["std_emission_mean"] for i in range(optimal_k)]
    bars = ax5.bar(
        range(optimal_k),
        std_means,
        color=colors,
        alpha=0.7,
        edgecolor="black",
        linewidth=2,
    )
    for bar, std_val in zip(bars, std_means):
        height = bar.get_height()
        ax5.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + height * 0.02,
            f"{std_val:.2f}",
            ha="center",
            va="bottom",
            fontsize=10,
            fontweight="bold",
        )
    ax5.set_xlabel("èšç±»ç¼–å·", fontsize=12, fontweight="bold")
    ax5.set_ylabel("ğŸ“Š ç‰¹å¾3: æ’æ”¾æ ‡å‡†å·® (æ³¢åŠ¨æ€§)", fontsize=12, fontweight="bold")
    ax5.set_title(
        "æ’æ”¾æ³¢åŠ¨æ€§ç‰¹å¾èšç±»å±•ç¤º", fontsize=12, fontweight="bold", color="darkviolet"
    )
    ax5.grid(True, alpha=0.3)

    # 6. æ•°æ®å®Œæ•´æ€§ç‰¹å¾å±•ç¤º (ç‰¹å¾6: å¹´ä»½æ•°é‡)
    ax6 = plt.subplot(2, 3, 6)
    years_means = [cluster_stats[i]["years_count_mean"] for i in range(optimal_k)]
    bars = ax6.bar(
        range(optimal_k),
        years_means,
        color=colors,
        alpha=0.7,
        edgecolor="black",
        linewidth=2,
    )
    for bar, years_val in zip(bars, years_means):
        height = bar.get_height()
        ax6.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + height * 0.02,
            f"{years_val:.1f}å¹´",
            ha="center",
            va="bottom",
            fontsize=10,
            fontweight="bold",
        )
    ax6.set_xlabel("èšç±»ç¼–å·", fontsize=12, fontweight="bold")
    ax6.set_ylabel("ğŸ“… ç‰¹å¾6: æ•°æ®å¹´ä»½æ•°é‡", fontsize=12, fontweight="bold")
    ax6.set_title(
        "æ•°æ®å®Œæ•´æ€§ç‰¹å¾èšç±»å±•ç¤º", fontsize=12, fontweight="bold", color="darkcyan"
    )
    ax6.grid(True, alpha=0.3)

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

    # åˆ›å»º7ç»´ç‰¹å¾ç»¼åˆå±•ç¤ºå›¾
    fig, ax = plt.subplots(figsize=(14, 10), subplot_kw=dict(polar=True))

    feature_labels_chinese = list(
        v.split(" ")[0] for v in feature_descriptions.values()
    )
    angles = np.linspace(0, 2 * np.pi, 7, endpoint=False).tolist()
    angles += angles[:1]

    for i in range(optimal_k):
        cluster_data = X_normalized[labels == i]
        if len(cluster_data) > 0:
            radar_values = cluster_data.mean(axis=0).tolist()
            radar_values += radar_values[:1]
            ax.plot(
                angles,
                radar_values,
                "o-",
                linewidth=3,
                label=f'èšç±»{i} ({cluster_stats[i]["count"]}åŸå¸‚)',
                color=colors[i],
                alpha=0.8,
                markersize=8,
            )
            ax.fill(angles, radar_values, alpha=0.15, color=colors[i])

    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(feature_labels_chinese, fontsize=12, fontweight="bold")
    ax.set_title(
        "7ç»´ç‰¹å¾ç»¼åˆé›·è¾¾å›¾\nå±•ç¤ºå„èšç±»åœ¨æ‰€æœ‰ç‰¹å¾ä¸Šçš„è¡¨ç°æ¨¡å¼ (0ä¸ºå¹³å‡æ°´å¹³)",
        fontsize=16,
        fontweight="bold",
        pad=30,
    )
    ax.legend(bbox_to_anchor=(1.2, 1), loc="upper left", fontsize=11)
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # (***ä¼˜åŒ–ç‚¹***) è¾“å‡ºç²¾ç®€åçš„è¯¦ç»†ç‰¹å¾èšç±»è¯´æ˜
    print("\n" + "ğŸ¯" * 30)
    print("ç‰¹å¾èšç±»è¯¦ç»†åˆ†ææŠ¥å‘Š")
    print("ğŸ¯" * 30)
    print(f"\nğŸ“‹ èšç±»æ–¹æ³•: K-meansç®—æ³• (K={optimal_k})")
    print("ğŸ“‹ èšç±»ä¾æ®: åŸºäºå·²è¯´æ˜çš„7ä¸ªç‰¹å¾è¿›è¡Œç»¼åˆåˆ†æã€‚")
    print("\nğŸ“Š èšç±»ç»“æœè§£è¯»:")
    print("-" * 60)

    for i in range(optimal_k):
        print(f"\nğŸ™ï¸  èšç±» {i} ç‰¹å¾ç”»åƒ (è¯¦ç»†æ•°æ®å¯¹æ¯”è¯·å‚è€ƒé›·è¾¾å›¾)")
        print("-" * 50)
        print(f"ğŸ“ åŸå¸‚æ•°é‡: {cluster_stats[i]['count']} ä¸ª")
        print(f"ğŸ“ ä»£è¡¨åŸå¸‚: {', '.join(cluster_stats[i]['cities'])} (åŠå…¶ä»–)")

        # (***ä¼˜åŒ–ç‚¹***) ç§»é™¤é‡å¤çš„7ç»´ç‰¹å¾ç½—åˆ—ï¼Œåªä¿ç•™æ ¸å¿ƒæ€»ç»“
        print(f"\nğŸ¯ æ ¸å¿ƒç‰¹å¾æ€»ç»“:")
        emission_level = (
            "é«˜æ’æ”¾"
            if cluster_stats[i]["mean_emission_mean"] > 30
            else "ä¸­æ’æ”¾" if cluster_stats[i]["mean_emission_mean"] > 10 else "ä½æ’æ”¾"
        )
        stability = (
            "æ³¢åŠ¨å¤§" if cluster_stats[i]["std_emission_mean"] > 20 else "ç›¸å¯¹ç¨³å®š"
        )
        print(
            f"  â€¢ æ’æ”¾æ°´å¹³: {emission_level} (å‡å€¼: {cluster_stats[i]['mean_emission_mean']:.2f})"
        )
        print(
            f"  â€¢ æ’æ”¾ç¨³å®šæ€§: {stability} (æ ‡å‡†å·®: {cluster_stats[i]['std_emission_mean']:.2f})"
        )
        print(
            f"  â€¢ å‘å±•è¶‹åŠ¿: {cluster_stats[i]['trend_desc']} (æ–œç‡: {cluster_stats[i]['trend_mean']:.3f})"
        )
        print(
            f"  â€¢ åœ°ç†åˆ†å¸ƒä¸­å¿ƒ: çº¬åº¦{cluster_stats[i]['lat_mean']:.1f}Â°, ç»åº¦{cluster_stats[i]['lon_mean']:.1f}Â°"
        )

    return results_df


# ... (ä» linear_trend_with_confidence åˆ° ensemble_prediction çš„å‡½æ•°ä¿æŒä¸å˜) ...
def linear_trend_with_confidence(time_series, future_years, confidence=0.95):
    """çº¿æ€§è¶‹åŠ¿é¢„æµ‹ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰"""
    x = np.arange(len(time_series))
    y = time_series["value"].values
    if len(x) < 2:
        return {"method": "Linear Trend (Not enough data)"}

    x_mean, y_mean = np.mean(x), np.mean(y)
    slope = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean) ** 2)
    intercept = y_mean - slope * x_mean

    future_x = np.arange(len(time_series), len(time_series) + future_years)
    future_pred = slope * future_x + intercept

    y_pred = slope * x + intercept
    ss_res = np.sum((y - y_pred) ** 2)
    ss_tot = np.sum((y - y_mean) ** 2)
    r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

    residuals = y - y_pred
    mse = np.mean(residuals**2)
    se = np.sqrt(
        mse * (1 + 1 / len(x) + (future_x - x_mean) ** 2 / np.sum((x - x_mean) ** 2))
    )
    margin_error = 1.96 * se

    return {
        "predictions": future_pred,
        "upper_bound": future_pred + margin_error,
        "lower_bound": future_pred - margin_error,
        "r_squared": r_squared,
        "slope": slope,
        "method": "Linear Trend",
    }


def polynomial_trend_prediction(time_series, future_years, degree=2):
    """å¤šé¡¹å¼è¶‹åŠ¿é¢„æµ‹"""
    x = np.arange(len(time_series))
    y = time_series["value"].values
    if len(x) < 4:
        return {"method": "Polynomial (Not enough data)"}

    best_degree, best_score = 1, -np.inf
    for d in range(1, min(4, len(time_series) // 3)):
        coeffs = np.polyfit(x, y, d)
        poly_pred = np.polyval(coeffs, x)
        ss_res = np.sum((y - poly_pred) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
        adj_r_squared = 1 - (1 - r_squared) * (len(y) - 1) / (len(y) - d - 1)
        if adj_r_squared > best_score:
            best_score, best_degree = adj_r_squared, d

    coeffs = np.polyfit(x, y, best_degree)
    future_x = np.arange(len(time_series), len(time_series) + future_years)
    future_pred = np.polyval(coeffs, future_x)

    return {
        "predictions": future_pred,
        "degree": best_degree,
        "r_squared": best_score,
        "method": f"Polynomial (d={best_degree})",
    }


def moving_average_prediction(time_series, future_years, window=None):
    """ç§»åŠ¨å¹³å‡é¢„æµ‹"""
    values = time_series["value"].values
    if len(values) < 2:
        return {"method": "Moving Average (Not enough data)"}

    if window is None:
        window = min(max(3, len(values) // 4), 12)
    if len(values) < window:
        window = len(values)

    moving_avg = np.convolve(values, np.ones(window) / window, mode="valid")

    if len(moving_avg) > 1:
        x = np.arange(len(moving_avg))
        x_mean, y_mean = np.mean(x), np.mean(moving_avg)
        slope = np.sum((x - x_mean) * (moving_avg - y_mean)) / np.sum((x - x_mean) ** 2)

        last_avg = moving_avg[-1]
        future_pred = [last_avg + slope * (i + 1) for i in range(future_years)]
        return {
            "predictions": np.array(future_pred),
            "window_size": window,
            "trend_slope": slope,
            "method": f"MA (win={window})",
        }
    else:
        return {
            "predictions": np.full(future_years, values[-1]),
            "method": "Simple Average",
        }


def exponential_smoothing_prediction(time_series, future_years, alpha=0.3):
    """æŒ‡æ•°å¹³æ»‘é¢„æµ‹"""
    values = time_series["value"].values
    if len(values) < 2:
        return {"method": "Exp. Smoothing (Not enough data)"}

    smoothed = [values[0]]
    for i in range(1, len(values)):
        smoothed.append(alpha * values[i] + (1 - alpha) * smoothed[i - 1])
    smoothed = np.array(smoothed)

    trend = smoothed[-1] - smoothed[-2] if len(smoothed) > 1 else 0
    last_value = smoothed[-1]
    future_pred = [last_value + trend * (i + 1) for i in range(future_years)]

    return {
        "predictions": np.array(future_pred),
        "alpha": alpha,
        "trend": trend,
        "method": f"Exp. Smooth (Î±={alpha:.2f})",
    }


def ensemble_prediction(predictions, future_years):
    """é›†æˆé¢„æµ‹ï¼ˆå¤šæ¨¡å‹å¹³å‡ï¼‰"""
    valid_predictions, weights, methods = [], [], []
    for method, pred_data in predictions.items():
        if method != "ensemble" and "predictions" in pred_data:
            valid_predictions.append(pred_data["predictions"])
            methods.append(pred_data["method"])
            weights.append(max(pred_data.get("r_squared", 0.5), 0.1))

    if not valid_predictions:
        return {"method": "Ensemble (No valid preds)"}

    weights = np.array(weights) / np.sum(weights)
    ensemble_pred = np.zeros(future_years)
    for pred, weight in zip(valid_predictions, weights):
        if len(pred) == future_years:
            ensemble_pred += weight * pred

    return {
        "predictions": ensemble_pred,
        "weights": dict(zip(methods, weights)),
        "method": "Ensemble Average",
    }


def perform_multiple_predictions(time_series, future_years):
    """æ‰§è¡Œå¤šç§é¢„æµ‹æ–¹æ³•"""
    predictions = {
        "linear": linear_trend_with_confidence(time_series, future_years),
        "polynomial": polynomial_trend_prediction(time_series, future_years),
        "moving_average": moving_average_prediction(time_series, future_years),
        "exponential": exponential_smoothing_prediction(time_series, future_years),
    }
    predictions["ensemble"] = ensemble_prediction(predictions, future_years)
    return predictions


def enhanced_prediction(data, results_df, future_years=5):
    """å¢å¼ºç‰ˆè¶‹åŠ¿é¢„æµ‹"""
    print(f"\næœªæ¥{future_years}å¹´å¢å¼ºè¶‹åŠ¿é¢„æµ‹:")
    print("=" * 80)

    for cluster_id in sorted(results_df["cluster"].unique()):
        cluster_cities = results_df[results_df["cluster"] == cluster_id][
            "city_name"
        ].tolist()
        cluster_data = data[data["city_name"].isin(cluster_cities)]

        print(f"\nèšç±» {cluster_id} - åŒ…å« {len(cluster_cities)} ä¸ªåŸå¸‚")
        print("-" * 60)

        time_series = cluster_data.groupby("year").agg({"value": "sum"}).reset_index()
        time_series["date"] = pd.to_datetime(time_series["year"], format="%Y")
        time_series = time_series.sort_values("date").reset_index(drop=True)

        if len(time_series) < 3:
            print(f"æ•°æ®ç‚¹å¤ªå°‘ ({len(time_series)} ä¸ª)ï¼Œè·³è¿‡é¢„æµ‹ã€‚")
            continue

        predictions = perform_multiple_predictions(time_series, future_years)
        visualize_enhanced_predictions(
            time_series, predictions, cluster_id, future_years
        )
        print_prediction_summary(predictions, time_series)


def visualize_enhanced_predictions(time_series, predictions, cluster_id, future_years):
    """å¯è§†åŒ–å¢å¼ºé¢„æµ‹ç»“æœ"""
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f"èšç±» {cluster_id} - å¤šæ¨¡å‹ç¢³æ’æ”¾é¢„æµ‹åˆ†æ", fontsize=16)

    historical_dates = time_series["date"]
    historical_values = time_series["value"]
    last_date = historical_dates.iloc[-1]
    future_dates = pd.date_range(
        start=last_date + pd.DateOffset(years=1), periods=future_years, freq="YS"
    )

    # 1. çº¿æ€§è¶‹åŠ¿
    ax1 = axes[0, 0]
    ax1.plot(historical_dates, historical_values, "b-", label="å†å²æ•°æ®", linewidth=2)
    if "linear" in predictions and "predictions" in predictions["linear"]:
        linear_pred = predictions["linear"]
        ax1.plot(
            future_dates,
            linear_pred["predictions"],
            "r--",
            label=f"çº¿æ€§é¢„æµ‹ (RÂ²={linear_pred['r_squared']:.3f})",
            linewidth=2,
        )
        ax1.fill_between(
            future_dates,
            linear_pred["lower_bound"],
            linear_pred["upper_bound"],
            alpha=0.3,
            color="red",
            label="95%ç½®ä¿¡åŒºé—´",
        )
    ax1.set_title("çº¿æ€§è¶‹åŠ¿é¢„æµ‹")
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.tick_params(axis="x", rotation=45)

    # 2. å¤šé¡¹å¼ä¸ç§»åŠ¨å¹³å‡
    ax2 = axes[0, 1]
    ax2.plot(historical_dates, historical_values, "b-", label="å†å²æ•°æ®", linewidth=2)
    if "polynomial" in predictions and "predictions" in predictions["polynomial"]:
        poly_pred = predictions["polynomial"]
        ax2.plot(
            future_dates,
            poly_pred["predictions"],
            "g--",
            label=f"{poly_pred['method']}",
            linewidth=2,
        )
    if (
        "moving_average" in predictions
        and "predictions" in predictions["moving_average"]
    ):
        ma_pred = predictions["moving_average"]
        ax2.plot(
            future_dates,
            ma_pred["predictions"],
            "m--",
            label=f"{ma_pred['method']}",
            linewidth=2,
        )
    ax2.set_title("å¤šé¡¹å¼ä¸ç§»åŠ¨å¹³å‡é¢„æµ‹")
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.tick_params(axis="x", rotation=45)

    # 3. æŒ‡æ•°å¹³æ»‘ä¸é›†æˆ
    ax3 = axes[1, 0]
    ax3.plot(historical_dates, historical_values, "b-", label="å†å²æ•°æ®", linewidth=2)
    if "exponential" in predictions and "predictions" in predictions["exponential"]:
        exp_pred = predictions["exponential"]
        ax3.plot(
            future_dates,
            exp_pred["predictions"],
            "orange",
            linestyle="--",
            label=f"{exp_pred['method']}",
            linewidth=2,
        )
    ax3.set_title("æŒ‡æ•°å¹³æ»‘é¢„æµ‹")
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.tick_params(axis="x", rotation=45)

    # 4. é›†æˆé¢„æµ‹å¯¹æ¯”
    ax4 = axes[1, 1]
    ax4.plot(historical_dates, historical_values, "b-", label="å†å²æ•°æ®", linewidth=3)
    colors = {"Linear": "red", "Polynomial": "green", "MA": "purple", "Exp.": "orange"}
    for method, pred_data in predictions.items():
        if "predictions" in pred_data and method != "ensemble":
            key_part = pred_data["method"].split(" ")[0]
            ax4.plot(
                future_dates,
                pred_data["predictions"],
                color=colors.get(key_part, "gray"),
                linestyle="--",
                alpha=0.7,
                label=pred_data["method"],
                linewidth=1.5,
            )
    if "ensemble" in predictions and "predictions" in predictions["ensemble"]:
        ensemble_pred = predictions["ensemble"]
        ax4.plot(
            future_dates,
            ensemble_pred["predictions"],
            "black",
            linestyle="-",
            label="é›†æˆé¢„æµ‹",
            linewidth=3,
        )
    ax4.set_title("æ‰€æœ‰é¢„æµ‹æ–¹æ³•å¯¹æ¯”")
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.tick_params(axis="x", rotation=45)

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()


def print_prediction_summary(predictions, time_series):
    """(***ä¼˜åŒ–ç‚¹***) æ‰“å°ç²¾ç®€åçš„é¢„æµ‹æ‘˜è¦, èšç„¦äºé›†æˆæ¨¡å‹"""
    historical_mean = time_series["value"].mean()
    print("é¢„æµ‹æ‘˜è¦ (åŸºäºå¤šæ¨¡å‹é›†æˆ):")
    print("-" * 50)

    ensemble_pred_data = predictions.get("ensemble")
    if ensemble_pred_data and "predictions" in ensemble_pred_data:
        future_mean = np.mean(ensemble_pred_data["predictions"])
        change_percent = (
            ((future_mean - historical_mean) / historical_mean) * 100
            if historical_mean != 0
            else 0
        )

        print(
            f"  é›†æˆæ¨¡å‹æœªæ¥ {len(ensemble_pred_data['predictions'])} å¹´å¹³å‡é¢„æµ‹å€¼: {future_mean:.2f}"
        )
        print(f"  ç›¸æ¯”å†å²å‡å€¼çš„å˜åŒ–: {change_percent:+.1f}%")

        if "weights" in ensemble_pred_data:
            weights_str = ", ".join(
                [
                    f"{k.split(' ')[0]}: {v:.1%}"
                    for k, v in ensemble_pred_data["weights"].items()
                ]
            )
            print(f"  å„æ¨¡å‹æƒé‡: {weights_str}")
    else:
        print("  æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„é›†æˆé¢„æµ‹ç»“æœã€‚")
    print()


# ==================== ä¸»æ‰§è¡Œå‡½æ•° ====================


def create_plots():
    """ä¸»å‡½æ•°"""
    print("å‡½æ•°å¼€å§‹æ‰§è¡Œï¼Œç¨å®‰å‹¿èº...")
    print("å¼€å§‹ç¢³æ’æ”¾K-meansèšç±»åˆ†æ...")

    # æ£€æŸ¥æ•°æ®
    print(f"æ•°æ®å½¢çŠ¶: {CHINA_DATA.shape}")
    print(f"åŸå¸‚æ•°é‡: {CHINA_DATA['city_name'].nunique()}")

    # æ‰§è¡Œèšç±»åˆ†æ
    results = analyze_and_visualize(CHINA_DATA)

    # æ‰§è¡Œå¢å¼ºç‰ˆè¶‹åŠ¿é¢„æµ‹
    enhanced_prediction(CHINA_DATA, results, future_years=5)

    print("\nåˆ†æå®Œæˆï¼")


# å¦‚æœæ‚¨æƒ³ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œæµ‹è¯•ï¼Œå¯ä»¥å–æ¶ˆä»¥ä¸‹ä»£ç çš„æ³¨é‡Š
# if __name__ == '__main__':
#     create_plots()
